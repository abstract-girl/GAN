{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77436cc4006b44dbb106a3fdd640312a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe9af3614f4a46cebe288b5cbf2f2e31",
              "IPY_MODEL_165d852df0a346a391a072747b8472a9",
              "IPY_MODEL_11b2ff3a707f4a9ca5c17d9de8505462"
            ],
            "layout": "IPY_MODEL_bbe2219085dc402a82ce2cf78ee50c49"
          }
        },
        "fe9af3614f4a46cebe288b5cbf2f2e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dff2d3742e5b49c4a3bf25d7913cd493",
            "placeholder": "​",
            "style": "IPY_MODEL_0cce1613c8964f93aec8760ef0dcdee2",
            "value": "Evaluating: 100%"
          }
        },
        "165d852df0a346a391a072747b8472a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f45d4c28cef4dc7a78cf08e4d0d0019",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa1738da20bf429db6bf280a4148d101",
            "value": 50
          }
        },
        "11b2ff3a707f4a9ca5c17d9de8505462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ca7180195bb4a019a6c5cfd299c3337",
            "placeholder": "​",
            "style": "IPY_MODEL_250a93a6a5db4922a550e3aad03e4f26",
            "value": " 50/50 [01:10&lt;00:00, 15.26it/s]"
          }
        },
        "bbe2219085dc402a82ce2cf78ee50c49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dff2d3742e5b49c4a3bf25d7913cd493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cce1613c8964f93aec8760ef0dcdee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f45d4c28cef4dc7a78cf08e4d0d0019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa1738da20bf429db6bf280a4148d101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ca7180195bb4a019a6c5cfd299c3337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250a93a6a5db4922a550e3aad03e4f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGQWhhkcf1H6",
        "outputId": "7babcece-78a1-416f-c001-12cde111f725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Setting up StyleGAN3 environment...\n",
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 212 (delta 99), reused 90 (delta 90), pack-reused 49 (from 1)\u001b[K\n",
            "Receiving objects: 100% (212/212), 4.16 MiB | 19.54 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n",
            "Downloading Van Gogh dataset...\n",
            "Processing images to 256x256...\n",
            "Found 2025 images to process\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 103/2025 [00:08<02:09, 14.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 100/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 201/2025 [00:16<02:28, 12.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 200/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 301/2025 [00:24<02:23, 12.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 300/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 401/2025 [00:32<01:51, 14.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 400/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 503/2025 [00:40<01:55, 13.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 500/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 603/2025 [00:45<01:20, 17.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 600/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 701/2025 [00:49<00:44, 29.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 700/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|███▉      | 800/2025 [00:53<00:42, 28.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 800/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 903/2025 [00:58<00:53, 20.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 900/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 1004/2025 [01:03<00:41, 24.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1000/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 1103/2025 [01:07<00:47, 19.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1100/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 1205/2025 [01:12<00:36, 22.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1200/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 1305/2025 [01:16<00:27, 26.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1300/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 1403/2025 [01:21<00:27, 22.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1400/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 1505/2025 [01:26<00:20, 24.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1500/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 1604/2025 [01:30<00:17, 24.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1600/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 1704/2025 [01:35<00:14, 22.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1700/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 1803/2025 [01:39<00:10, 21.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1800/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 1902/2025 [01:45<00:06, 17.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1900/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 2002/2025 [01:52<00:02, 11.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2000/2025 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2025/2025 [01:53<00:00, 17.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating dataset zip...\n",
            "100% 2025/2025 [00:14<00:00, 136.28it/s]\n",
            "Downloading compatible pre-trained model...\n",
            "--2025-05-14 11:30:42--  https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 52.10.4.28, 54.203.101.202\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|52.10.4.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://xfiles.ngc.nvidia.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl?ssec-algo=AES256&versionId=IXmECuKSHP.HB4h6M9LD9rXen0blAI6D&ssec-key=HOzuokpWKp%2B9LrAL8AzTdgcZqBezpaXVW56aLp8goLxNbgTi8ukLAwiCy3KzXbgOvwwMazgvbuQ9tR5PrdnuJbrLUBRavJA36NpR1CKr3mkQpgMsciegJLA4ZVYRGWx4bGD7owKXobiWNUmpo%2Far3TOlsyJORVG75aZw3X1ncjZVk1kBfFYNGkRk2mguzm%2Bsuy9VK58mthW8YAbHP9kVGHYBVUj4b38R%2BtMI7r6XZrQuG7ZO9bZid8R8WMA6kEkrSVrV5WfFAGISd8mc7GiG26ivxdSa5BNniHHWoX3ldp2%2BkPcs8Txf6GwFN2swWCrXhpxS61tNFI6E1XF38hw6uCEt85SVAOcx9OV5Bo2pK7gMTEOGNd8QTs%2BhRQCMRd%2BRMVhfZ7jCQWkPQa4%2FaWUCg%2Fhs12CQU2ffWMR%2F0rG0EWmAZXfYvrfwR6iguDYEAFXxonQVSymArAMr5%2BXi373SEU97IlKEyqHehREUDawaTJ7wPWOzaN1m116sCAawmX0y&Signature=wB~kM4LO2biGoCk4xhmQLzKNkLcyUrsEFaCRNELC-SMYlTfq9b6XM2VM0VBKzLdjKxqwstuPx2toSor9KfKKeS8bsStwDkxe1V5PqO9Vm7AypcY4R6Q8g3~nvJ1RD1leZ3tE5VcIKItihaFe~sMBacPFacYPli6JUWM26tv1xgOsmYolGe-bxGeYAUUbhlxA-UsArR4VXvOiOVz7W2P1uINHBUnUtafcLZbaw0uhxDEbpPUyIzI-5OsJpQQ7CrKYtYVQPKmEKYVtJxH9wDuLewUAWXxSn2U1zuK6KURNpsB18RBEupOTgtuTtjQlMkmobZxhKJy99gvAhcN0O1xmSw__&kid=bXJrLWU3OGM1M2FhZjE4YzRiNmJiNjlkYmRhZjcxNjA3YWEw&Expires=1747308642&Key-Pair-Id=KCX06E8E9L60W&ssec-enabled=true [following]\n",
            "--2025-05-14 11:30:42--  https://xfiles.ngc.nvidia.com/org/nvidia/team/research/models/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl?ssec-algo=AES256&versionId=IXmECuKSHP.HB4h6M9LD9rXen0blAI6D&ssec-key=HOzuokpWKp%2B9LrAL8AzTdgcZqBezpaXVW56aLp8goLxNbgTi8ukLAwiCy3KzXbgOvwwMazgvbuQ9tR5PrdnuJbrLUBRavJA36NpR1CKr3mkQpgMsciegJLA4ZVYRGWx4bGD7owKXobiWNUmpo%2Far3TOlsyJORVG75aZw3X1ncjZVk1kBfFYNGkRk2mguzm%2Bsuy9VK58mthW8YAbHP9kVGHYBVUj4b38R%2BtMI7r6XZrQuG7ZO9bZid8R8WMA6kEkrSVrV5WfFAGISd8mc7GiG26ivxdSa5BNniHHWoX3ldp2%2BkPcs8Txf6GwFN2swWCrXhpxS61tNFI6E1XF38hw6uCEt85SVAOcx9OV5Bo2pK7gMTEOGNd8QTs%2BhRQCMRd%2BRMVhfZ7jCQWkPQa4%2FaWUCg%2Fhs12CQU2ffWMR%2F0rG0EWmAZXfYvrfwR6iguDYEAFXxonQVSymArAMr5%2BXi373SEU97IlKEyqHehREUDawaTJ7wPWOzaN1m116sCAawmX0y&Signature=wB~kM4LO2biGoCk4xhmQLzKNkLcyUrsEFaCRNELC-SMYlTfq9b6XM2VM0VBKzLdjKxqwstuPx2toSor9KfKKeS8bsStwDkxe1V5PqO9Vm7AypcY4R6Q8g3~nvJ1RD1leZ3tE5VcIKItihaFe~sMBacPFacYPli6JUWM26tv1xgOsmYolGe-bxGeYAUUbhlxA-UsArR4VXvOiOVz7W2P1uINHBUnUtafcLZbaw0uhxDEbpPUyIzI-5OsJpQQ7CrKYtYVQPKmEKYVtJxH9wDuLewUAWXxSn2U1zuK6KURNpsB18RBEupOTgtuTtjQlMkmobZxhKJy99gvAhcN0O1xmSw__&kid=bXJrLWU3OGM1M2FhZjE4YzRiNmJiNjlkYmRhZjcxNjA3YWEw&Expires=1747308642&Key-Pair-Id=KCX06E8E9L60W&ssec-enabled=true\n",
            "Resolving xfiles.ngc.nvidia.com (xfiles.ngc.nvidia.com)... 3.171.22.96, 3.171.22.57, 3.171.22.62, ...\n",
            "Connecting to xfiles.ngc.nvidia.com (xfiles.ngc.nvidia.com)|3.171.22.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 222477563 (212M) [application/x-zerosize]\n",
            "Saving to: ‘/content/van_gogh_gan/models/stylegan3_pretrained.pkl’\n",
            "\n",
            "/content/van_gogh_g 100%[===================>] 212.17M  70.3MB/s    in 3.0s    \n",
            "\n",
            "2025-05-14 11:30:46 (70.3 MB/s) - ‘/content/van_gogh_gan/models/stylegan3_pretrained.pkl’ saved [222477563/222477563]\n",
            "\n",
            "Starting fine-tuning with StyleGAN3...\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 65536,\n",
            "    \"channel_max\": 1024,\n",
            "    \"magnitude_ema_beta\": 0.9994456359721023,\n",
            "    \"conv_kernel\": 1,\n",
            "    \"use_radial_filters\": true\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 10.0,\n",
            "    \"blur_init_sigma\": 0,\n",
            "    \"blur_fade_kimg\": 100.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/van_gogh_gan/data/vangogh.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 2025,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 1000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"/content/van_gogh_gan/models/stylegan3_pretrained.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"/content/van_gogh_gan/models/00000-stylegan3-r-vangogh-gpus1-batch16-gamma10\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/van_gogh_gan/models/00000-stylegan3-r-vangogh-gpus1-batch16-gamma10\n",
            "Number of GPUs:      1\n",
            "Batch size:          16 images\n",
            "Training duration:   1000 kimg\n",
            "Dataset path:        /content/van_gogh_gan/data/vangogh.zip\n",
            "Dataset size:        2025 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py:77: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\n",
            "\n",
            "Num images:  4050\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/van_gogh_gan/models/stylegan3_pretrained.pkl\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stylegan3/train.py\", line 286, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "    ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1161, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1082, in main\n",
            "    rv = self.invoke(ctx)\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 1443, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/click/core.py\", line 788, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/stylegan3/train.py\", line 281, in main\n",
            "    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n",
            "  File \"/content/stylegan3/train.py\", line 96, in launch_training\n",
            "    subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n",
            "  File \"/content/stylegan3/train.py\", line 47, in subprocess_fn\n",
            "    training_loop.training_loop(rank=rank, **c)\n",
            "  File \"/content/stylegan3/training/training_loop.py\", line 162, in training_loop\n",
            "    misc.copy_params_and_buffers(resume_data[name], module, require_all=False)\n",
            "  File \"/content/stylegan3/torch_utils/misc.py\", line 162, in copy_params_and_buffers\n",
            "    tensor.copy_(src_tensors[name].detach()).requires_grad_(tensor.requires_grad)\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: The size of tensor a (256) must match the size of tensor b (128) at non-singleton dimension 1\n",
            "No model snapshots found. Checking for other model files...\n",
            "No trained model snapshots found. Generating samples with pretrained model...\n",
            "Loading networks from \"/content/van_gogh_gan/models/stylegan3_pretrained.pkl\"...\n",
            "Generating image for seed 0 (0/16) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Done.\n",
            "Generating image for seed 1 (1/16) ...\n",
            "Generating image for seed 2 (2/16) ...\n",
            "Generating image for seed 3 (3/16) ...\n",
            "Generating image for seed 4 (4/16) ...\n",
            "Generating image for seed 5 (5/16) ...\n",
            "Generating image for seed 6 (6/16) ...\n",
            "Generating image for seed 7 (7/16) ...\n",
            "Generating image for seed 8 (8/16) ...\n",
            "Generating image for seed 9 (9/16) ...\n",
            "Generating image for seed 10 (10/16) ...\n",
            "Generating image for seed 11 (11/16) ...\n",
            "Generating image for seed 12 (12/16) ...\n",
            "Generating image for seed 13 (13/16) ...\n",
            "Generating image for seed 14 (14/16) ...\n",
            "Generating image for seed 15 (15/16) ...\n",
            "Backing up results to Google Drive...\n",
            "\n",
            "Samples generated with pretrained model saved to: /content/drive/MyDrive/van_gogh_gan/results/samples/\n",
            "Pipeline completed!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "base_dir = \"/content/van_gogh_gan\"\n",
        "!rm -rf {base_dir}\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "os.makedirs(f\"{base_dir}/data\", exist_ok=True)\n",
        "os.makedirs(f\"{base_dir}/data/raw\", exist_ok=True)\n",
        "os.makedirs(f\"{base_dir}/data/processed\", exist_ok=True)\n",
        "os.makedirs(f\"{base_dir}/models\", exist_ok=True)\n",
        "os.makedirs(f\"{base_dir}/results\", exist_ok=True)\n",
        "os.makedirs(f\"{base_dir}/results/samples\", exist_ok=True)\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "drive_dir = \"/content/drive/MyDrive/van_gogh_gan\"\n",
        "os.makedirs(drive_dir, exist_ok=True)\n",
        "\n",
        "print(\"Setting up StyleGAN3 environment...\")\n",
        "\n",
        "!pip install -q ninja scipy opencv-python matplotlib lpips kagglehub torch torchvision\n",
        "\n",
        "!rm -rf stylegan3\n",
        "!git clone https://github.com/NVlabs/stylegan3.git\n",
        "sys.path.append(os.path.abspath(\"stylegan3\"))\n",
        "\n",
        "print(\"Downloading Van Gogh dataset...\")\n",
        "import kagglehub\n",
        "dataset_path = kagglehub.dataset_download(\"ipythonx/van-gogh-paintings\")\n",
        "\n",
        "print(\"Processing images to 256x256...\")\n",
        "processed_dir = f\"{base_dir}/data/processed\"\n",
        "\n",
        "paintings = []\n",
        "for ext in ['.jpg', '.jpeg', '.png']:\n",
        "    paintings.extend(glob.glob(f\"{dataset_path}/**/*{ext}\", recursive=True))\n",
        "\n",
        "print(f\"Found {len(paintings)} images to process\")\n",
        "\n",
        "for i, img_path in enumerate(tqdm(paintings)):\n",
        "    try:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        width, height = img.size\n",
        "        size = min(width, height)\n",
        "        left = (width - size) // 2\n",
        "        top = (height - size) // 2\n",
        "        img = img.crop((left, top, left + size, top + size))\n",
        "\n",
        "        img = img.resize((256, 256), Image.LANCZOS)\n",
        "\n",
        "        img.save(f\"{processed_dir}/img_{i:04d}.png\")\n",
        "\n",
        "        if i % 100 == 0 and i > 0:\n",
        "            print(f\"Processed {i}/{len(paintings)} images\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path}: {e}\")\n",
        "\n",
        "print(\"Creating dataset zip...\")\n",
        "!python stylegan3/dataset_tool.py --source={processed_dir} --dest={base_dir}/data/vangogh.zip\n",
        "\n",
        "print(\"Downloading compatible pre-trained model...\")\n",
        "!wget -nc https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-256x256.pkl \\\n",
        "     -O {base_dir}/models/stylegan3_pretrained.pkl\n",
        "\n",
        "print(\"Starting fine-tuning with StyleGAN3...\")\n",
        "!python stylegan3/train.py --outdir={base_dir}/models \\\n",
        "    --data={base_dir}/data/vangogh.zip \\\n",
        "    --resume={base_dir}/models/stylegan3_pretrained.pkl \\\n",
        "    --gpus=1 --batch=16 --gamma=10 --mirror=1 \\\n",
        "    --snap=50 --kimg=1000 \\\n",
        "    --metrics=none \\\n",
        "    --cfg=stylegan3-r \\\n",
        "    --cbase=16384\n",
        "\n",
        "model_snapshots = glob.glob(f\"{base_dir}/models/**/network-snapshot-*.pkl\", recursive=True)\n",
        "if not model_snapshots:\n",
        "    print(\"No model snapshots found. Checking for other model files...\")\n",
        "    model_snapshots = glob.glob(f\"{base_dir}/models/**/*.pkl\", recursive=True)\n",
        "    model_snapshots = [m for m in model_snapshots if not m.endswith('stylegan3_pretrained.pkl')]\n",
        "\n",
        "if model_snapshots:\n",
        "    latest_model = max(model_snapshots, key=os.path.getctime)\n",
        "    print(f\"Using model: {latest_model}\")\n",
        "\n",
        "    print(\"Generating samples...\")\n",
        "\n",
        "    !python stylegan3/gen_images.py \\\n",
        "        --network={latest_model} \\\n",
        "        --seeds=0-15 \\\n",
        "        --outdir={base_dir}/results/samples \\\n",
        "        --trunc=0.7\n",
        "\n",
        "    print(\"Backing up results to Google Drive...\")\n",
        "    !mkdir -p {drive_dir}/results/samples\n",
        "    !cp {base_dir}/results/samples/*.png {drive_dir}/results/samples/ 2>/dev/null || true\n",
        "    !cp {latest_model} {drive_dir}/\n",
        "\n",
        "    print(f\"\\nAll results saved to Google Drive at: {drive_dir}\")\n",
        "    print(f\"Generated images are in: {drive_dir}/results/samples/\")\n",
        "    print(f\"The trained model is saved as: {drive_dir}/{os.path.basename(latest_model)}\")\n",
        "else:\n",
        "    print(\"No trained model snapshots found. Generating samples with pretrained model...\")\n",
        "\n",
        "    !python stylegan3/gen_images.py \\\n",
        "        --network={base_dir}/models/stylegan3_pretrained.pkl \\\n",
        "        --seeds=0-15 \\\n",
        "        --outdir={base_dir}/results/samples \\\n",
        "        --trunc=0.7\n",
        "\n",
        "    print(\"Backing up results to Google Drive...\")\n",
        "    !mkdir -p {drive_dir}/results/samples\n",
        "    !cp {base_dir}/results/samples/*.png {drive_dir}/results/samples/ 2>/dev/null || true\n",
        "\n",
        "    print(f\"\\nSamples generated with pretrained model saved to: {drive_dir}/results/samples/\")\n",
        "\n",
        "print(\"Pipeline completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/betas=\\[0,0.99\\]/betas=[0.0,0.99]/g' stylegan3/train.py\n",
        "\n",
        "print(\"Starting fine-tuning with StyleGAN3...\")\n",
        "!python stylegan3/train.py --outdir={base_dir}/models \\\n",
        "    --data={base_dir}/data/vangogh.zip \\\n",
        "    --resume={base_dir}/models/stylegan3_pretrained.pkl \\\n",
        "    --gpus=1 --batch=16 --gamma=10 --mirror=1 \\\n",
        "    --snap=50 --kimg=1000 --metrics=none \\\n",
        "    --cfg=stylegan3-r --cbase=16384\n",
        "\n",
        "model_snapshots = glob.glob(f\"{base_dir}/models/**/network-snapshot-*.pkl\", recursive=True)\n",
        "if not model_snapshots:\n",
        "    print(\"No model snapshots found. Checking for other model files...\")\n",
        "    model_snapshots = glob.glob(f\"{base_dir}/models/**/*.pkl\", recursive=True)\n",
        "    model_snapshots = [m for m in model_snapshots if not m.endswith('stylegan3_pretrained.pkl')]\n",
        "\n",
        "if model_snapshots:\n",
        "    latest_model = max(model_snapshots, key=os.path.getctime)\n",
        "    print(f\"Using model: {latest_model}\")\n",
        "\n",
        "    print(\"Generating samples...\")\n",
        "\n",
        "    !python stylegan3/gen_images.py \\\n",
        "        --network={latest_model} \\\n",
        "        --seeds=0-15 \\\n",
        "        --outdir={base_dir}/results/samples \\\n",
        "        --trunc=0.7\n",
        "\n",
        "    print(\"Backing up results to Google Drive...\")\n",
        "    !mkdir -p {drive_dir}/results/samples\n",
        "    !cp {base_dir}/results/samples/*.png {drive_dir}/results/samples/ 2>/dev/null || true\n",
        "    !cp {latest_model} {drive_dir}/\n",
        "\n",
        "    print(f\"\\nAll results saved to Google Drive at: {drive_dir}\")\n",
        "    print(f\"Generated images are in: {drive_dir}/results/samples/\")\n",
        "    print(f\"The trained model is saved as: {drive_dir}/{os.path.basename(latest_model)}\")\n",
        "else:\n",
        "    print(\"No trained model snapshots found. Generating samples with pretrained model...\")\n",
        "\n",
        "    !python stylegan3/gen_images.py \\\n",
        "        --network={base_dir}/models/stylegan3_pretrained.pkl \\\n",
        "        --seeds=0-15 \\\n",
        "        --outdir={base_dir}/results/samples \\\n",
        "        --trunc=0.7\n",
        "\n",
        "    print(\"Backing up results to Google Drive...\")\n",
        "    !mkdir -p {drive_dir}/results/samples\n",
        "    !cp {base_dir}/results/samples/*.png {drive_dir}/results/samples/ 2>/dev/null || true\n",
        "\n",
        "    print(f\"\\nSamples generated with pretrained model saved to: {drive_dir}/results/samples/\")\n",
        "\n",
        "print(\"Pipeline completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5xp_dMtlweS",
        "outputId": "f9b3d288-b529-471b-a797-09974b8e9f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning with StyleGAN3...\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 1024,\n",
            "    \"magnitude_ema_beta\": 0.9994456359721023,\n",
            "    \"conv_kernel\": 1,\n",
            "    \"use_radial_filters\": true\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0.0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0.0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 10.0,\n",
            "    \"blur_init_sigma\": 0,\n",
            "    \"blur_fade_kimg\": 100.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/van_gogh_gan/data/vangogh.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 2025,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [],\n",
            "  \"total_kimg\": 1000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"resume_pkl\": \"/content/van_gogh_gan/models/stylegan3_pretrained.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"ema_rampup\": null,\n",
            "  \"run_dir\": \"/content/van_gogh_gan/models/00002-stylegan3-r-vangogh-gpus1-batch16-gamma10\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/van_gogh_gan/models/00002-stylegan3-r-vangogh-gpus1-batch16-gamma10\n",
            "Number of GPUs:      1\n",
            "Batch size:          16 images\n",
            "Training duration:   1000 kimg\n",
            "Dataset path:        /content/van_gogh_gan/data/vangogh.zip\n",
            "Dataset size:        2025 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py:77: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\n",
            "\n",
            "Num images:  4050\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"/content/van_gogh_gan/models/stylegan3_pretrained.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [16, 512]            float32 \n",
            "mapping.fc1                   262656      -        [16, 512]            float32 \n",
            "mapping                       -           512      [16, 16, 512]        float32 \n",
            "synthesis.input.affine        2052        -        [16, 4]              float32 \n",
            "synthesis.input               1048576     3081     [16, 1024, 36, 36]   float32 \n",
            "synthesis.L0_36_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L0_36_1024          1049600     157      [16, 1024, 36, 36]   float32 \n",
            "synthesis.L1_36_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L1_36_1024          1049600     157      [16, 1024, 36, 36]   float32 \n",
            "synthesis.L2_36_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L2_36_1024          1049600     157      [16, 1024, 36, 36]   float32 \n",
            "synthesis.L3_52_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L3_52_1024          1049600     169      [16, 1024, 52, 52]   float16 \n",
            "synthesis.L4_52_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L4_52_1024          1049600     157      [16, 1024, 52, 52]   float16 \n",
            "synthesis.L5_84_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L5_84_1024          1049600     169      [16, 1024, 84, 84]   float16 \n",
            "synthesis.L6_84_1024.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L6_84_1024          1049600     157      [16, 1024, 84, 84]   float16 \n",
            "synthesis.L7_148_724.affine   525312      -        [16, 1024]           float32 \n",
            "synthesis.L7_148_724          742100      169      [16, 724, 148, 148]  float16 \n",
            "synthesis.L8_148_512.affine   371412      -        [16, 724]            float32 \n",
            "synthesis.L8_148_512          371200      157      [16, 512, 148, 148]  float16 \n",
            "synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L9_148_362          185706      157      [16, 362, 148, 148]  float16 \n",
            "synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n",
            "synthesis.L10_276_256         92928       169      [16, 256, 276, 276]  float16 \n",
            "synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n",
            "synthesis.L11_276_181         46517       157      [16, 181, 276, 276]  float16 \n",
            "synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n",
            "synthesis.L12_276_128         23296       25       [16, 128, 276, 276]  float16 \n",
            "synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n",
            "synthesis.L13_256_128         16512       25       [16, 128, 256, 256]  float16 \n",
            "synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n",
            "synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n",
            "synthesis                     -           -        [16, 3, 256, 256]    float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         15779565    5576     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   256         16       [16, 64, 256, 256]   float16 \n",
            "b256.skip      8192        16       [16, 128, 128, 128]  float16 \n",
            "b256.conv0     36928       16       [16, 64, 256, 256]   float16 \n",
            "b256.conv1     73856       16       [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      32768       16       [16, 256, 64, 64]    float16 \n",
            "b128.conv0     147584      16       [16, 128, 128, 128]  float16 \n",
            "b128.conv1     295168      16       [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       131072      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      590080      16       [16, 256, 64, 64]    float16 \n",
            "b64.conv1      1180160     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          24001089    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2025-05-14 11:46:20.087377: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-14 11:46:20.104638: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747223180.126760   10330 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747223180.133345   10330 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-14 11:46:20.155272: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Training for 1000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 59s          sec/tick 10.7    sec/kimg 667.05  maintenance 48.6   cpumem 3.30   gpumem 12.21  reserved 12.41  augment 0.000\n",
            "tick 1     kimg 4.0      time 3m 37s       sec/tick 139.7   sec/kimg 34.93   maintenance 18.2   cpumem 3.72   gpumem 8.30   reserved 15.15  augment 0.020\n",
            "tick 2     kimg 8.0      time 5m 57s       sec/tick 139.9   sec/kimg 34.98   maintenance 0.0    cpumem 3.72   gpumem 8.30   reserved 15.15  augment 0.040\n",
            "tick 3     kimg 12.0     time 8m 17s       sec/tick 139.9   sec/kimg 34.98   maintenance 0.0    cpumem 3.72   gpumem 8.40   reserved 15.15  augment 0.046\n",
            "tick 4     kimg 16.0     time 10m 37s      sec/tick 140.0   sec/kimg 34.99   maintenance 0.0    cpumem 3.72   gpumem 8.31   reserved 15.15  augment 0.066\n",
            "tick 5     kimg 20.0     time 12m 57s      sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.72   gpumem 8.35   reserved 15.15  augment 0.077\n",
            "tick 6     kimg 24.0     time 15m 17s      sec/tick 139.9   sec/kimg 34.98   maintenance 0.0    cpumem 3.72   gpumem 8.32   reserved 15.15  augment 0.081\n",
            "tick 7     kimg 28.0     time 17m 37s      sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.72   gpumem 8.34   reserved 15.15  augment 0.078\n",
            "tick 8     kimg 32.0     time 19m 57s      sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.35   reserved 15.15  augment 0.079\n",
            "tick 9     kimg 36.0     time 22m 17s      sec/tick 139.9   sec/kimg 34.97   maintenance 0.1    cpumem 3.73   gpumem 8.34   reserved 15.15  augment 0.079\n",
            "tick 10    kimg 40.0     time 24m 37s      sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.15  augment 0.077\n",
            "tick 11    kimg 44.0     time 26m 57s      sec/tick 139.9   sec/kimg 34.97   maintenance 0.0    cpumem 3.73   gpumem 8.32   reserved 15.15  augment 0.076\n",
            "tick 12    kimg 48.0     time 29m 17s      sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.15  augment 0.077\n",
            "tick 13    kimg 52.0     time 31m 37s      sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.36   reserved 15.15  augment 0.079\n",
            "tick 14    kimg 56.0     time 33m 57s      sec/tick 139.9   sec/kimg 34.98   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.15  augment 0.080\n",
            "tick 15    kimg 60.0     time 36m 17s      sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.34   reserved 15.16  augment 0.088\n",
            "tick 16    kimg 64.0     time 38m 37s      sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.35   reserved 15.16  augment 0.092\n",
            "tick 17    kimg 68.0     time 40m 57s      sec/tick 140.0   sec/kimg 34.99   maintenance 0.1    cpumem 3.73   gpumem 8.35   reserved 15.16  augment 0.097\n",
            "tick 18    kimg 72.0     time 43m 17s      sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.37   reserved 15.16  augment 0.100\n",
            "tick 19    kimg 76.0     time 45m 37s      sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.36   reserved 15.16  augment 0.103\n",
            "tick 20    kimg 80.0     time 47m 58s      sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.104\n",
            "tick 21    kimg 84.0     time 50m 18s      sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.37   reserved 15.16  augment 0.106\n",
            "tick 22    kimg 88.0     time 52m 38s      sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.34   reserved 15.16  augment 0.104\n",
            "tick 23    kimg 92.0     time 54m 58s      sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.73   gpumem 8.36   reserved 15.16  augment 0.116\n",
            "tick 24    kimg 96.0     time 57m 18s      sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.120\n",
            "tick 25    kimg 100.0    time 59m 38s      sec/tick 140.0   sec/kimg 35.00   maintenance 0.1    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.120\n",
            "tick 26    kimg 104.0    time 1h 01m 58s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.37   reserved 15.16  augment 0.119\n",
            "tick 27    kimg 108.0    time 1h 04m 18s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.34   reserved 15.16  augment 0.127\n",
            "tick 28    kimg 112.0    time 1h 06m 39s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.126\n",
            "tick 29    kimg 116.0    time 1h 08m 59s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.36   reserved 15.16  augment 0.129\n",
            "tick 30    kimg 120.0    time 1h 11m 19s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.36   reserved 15.16  augment 0.123\n",
            "tick 31    kimg 124.0    time 1h 13m 39s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.35   reserved 15.16  augment 0.121\n",
            "tick 32    kimg 128.0    time 1h 15m 59s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.34   reserved 15.16  augment 0.125\n",
            "tick 33    kimg 132.0    time 1h 18m 19s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.1    cpumem 3.73   gpumem 8.36   reserved 15.16  augment 0.122\n",
            "tick 34    kimg 136.0    time 1h 20m 39s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.16  augment 0.118\n",
            "tick 35    kimg 140.0    time 1h 22m 59s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.37   reserved 15.16  augment 0.132\n",
            "tick 36    kimg 144.0    time 1h 25m 20s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.129\n",
            "tick 37    kimg 148.0    time 1h 27m 40s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.130\n",
            "tick 38    kimg 152.0    time 1h 30m 00s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.36   reserved 15.16  augment 0.125\n",
            "tick 39    kimg 156.0    time 1h 32m 20s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.37   reserved 15.16  augment 0.128\n",
            "tick 40    kimg 160.0    time 1h 34m 40s   sec/tick 140.1   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.41   reserved 15.16  augment 0.134\n",
            "tick 41    kimg 164.0    time 1h 37m 00s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.1    cpumem 3.73   gpumem 8.39   reserved 15.16  augment 0.135\n",
            "tick 42    kimg 168.0    time 1h 39m 20s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.73   gpumem 8.36   reserved 15.16  augment 0.136\n",
            "tick 43    kimg 172.0    time 1h 41m 40s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.36   reserved 15.16  augment 0.143\n",
            "tick 44    kimg 176.0    time 1h 44m 01s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.144\n",
            "tick 45    kimg 180.0    time 1h 46m 21s   sec/tick 140.1   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.36   reserved 15.16  augment 0.145\n",
            "tick 46    kimg 184.0    time 1h 48m 41s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.41   reserved 15.16  augment 0.141\n",
            "tick 47    kimg 188.0    time 1h 51m 01s   sec/tick 140.3   sec/kimg 35.07   maintenance 0.0    cpumem 3.73   gpumem 8.37   reserved 15.16  augment 0.143\n",
            "tick 48    kimg 192.0    time 1h 53m 21s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.137\n",
            "tick 49    kimg 196.0    time 1h 55m 41s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.1    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.141\n",
            "tick 50    kimg 200.0    time 1h 58m 02s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.16  augment 0.140\n",
            "tick 51    kimg 204.0    time 2h 00m 36s   sec/tick 140.1   sec/kimg 35.04   maintenance 14.1   cpumem 3.74   gpumem 8.39   reserved 15.16  augment 0.140\n",
            "tick 52    kimg 208.0    time 2h 02m 56s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.74   gpumem 8.39   reserved 15.16  augment 0.139\n",
            "tick 53    kimg 212.0    time 2h 05m 16s   sec/tick 140.3   sec/kimg 35.06   maintenance 0.0    cpumem 3.74   gpumem 8.37   reserved 15.16  augment 0.142\n",
            "tick 54    kimg 216.0    time 2h 07m 36s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.74   gpumem 8.40   reserved 15.16  augment 0.137\n",
            "tick 55    kimg 220.0    time 2h 09m 57s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.74   gpumem 8.38   reserved 15.16  augment 0.137\n",
            "tick 56    kimg 224.0    time 2h 12m 17s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.74   gpumem 8.36   reserved 15.16  augment 0.142\n",
            "tick 57    kimg 228.0    time 2h 14m 37s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.1    cpumem 3.74   gpumem 8.38   reserved 15.16  augment 0.143\n",
            "tick 58    kimg 232.0    time 2h 16m 57s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.74   gpumem 8.40   reserved 15.16  augment 0.139\n",
            "tick 59    kimg 236.0    time 2h 19m 17s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.74   gpumem 8.40   reserved 15.16  augment 0.142\n",
            "tick 60    kimg 240.0    time 2h 21m 38s   sec/tick 140.3   sec/kimg 35.06   maintenance 0.0    cpumem 3.74   gpumem 8.38   reserved 15.16  augment 0.152\n",
            "tick 61    kimg 244.0    time 2h 23m 58s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.74   gpumem 8.35   reserved 15.16  augment 0.154\n",
            "tick 62    kimg 248.0    time 2h 26m 18s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.74   gpumem 8.42   reserved 15.16  augment 0.156\n",
            "tick 63    kimg 252.0    time 2h 28m 38s   sec/tick 140.3   sec/kimg 35.07   maintenance 0.0    cpumem 3.74   gpumem 8.37   reserved 15.16  augment 0.161\n",
            "tick 64    kimg 256.0    time 2h 30m 58s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.74   gpumem 8.38   reserved 15.16  augment 0.168\n",
            "tick 65    kimg 260.0    time 2h 33m 19s   sec/tick 140.1   sec/kimg 35.01   maintenance 0.1    cpumem 3.74   gpumem 8.37   reserved 15.16  augment 0.170\n",
            "tick 66    kimg 264.0    time 2h 35m 39s   sec/tick 140.3   sec/kimg 35.07   maintenance 0.0    cpumem 3.74   gpumem 8.50   reserved 15.16  augment 0.163\n",
            "tick 67    kimg 268.0    time 2h 37m 59s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.74   gpumem 8.38   reserved 15.16  augment 0.164\n",
            "tick 68    kimg 272.0    time 2h 40m 19s   sec/tick 140.3   sec/kimg 35.07   maintenance 0.0    cpumem 3.74   gpumem 8.38   reserved 15.16  augment 0.163\n",
            "tick 69    kimg 276.0    time 2h 42m 39s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.74   gpumem 8.43   reserved 15.16  augment 0.164\n",
            "tick 70    kimg 280.0    time 2h 45m 00s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.74   gpumem 8.40   reserved 15.16  augment 0.157\n",
            "tick 71    kimg 284.0    time 2h 47m 20s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.74   gpumem 8.36   reserved 15.16  augment 0.166\n",
            "tick 72    kimg 288.0    time 2h 49m 40s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.74   gpumem 8.38   reserved 15.16  augment 0.159\n",
            "tick 73    kimg 292.0    time 2h 52m 00s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.1    cpumem 3.74   gpumem 8.35   reserved 15.16  augment 0.157\n",
            "tick 74    kimg 296.0    time 2h 54m 20s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.74   gpumem 8.37   reserved 15.16  augment 0.158\n",
            "tick 75    kimg 300.0    time 2h 56m 41s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.74   gpumem 8.42   reserved 15.16  augment 0.165\n",
            "tick 76    kimg 304.0    time 2h 59m 01s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.74   gpumem 8.40   reserved 15.16  augment 0.163\n",
            "tick 77    kimg 308.0    time 3h 01m 21s   sec/tick 140.3   sec/kimg 35.07   maintenance 0.0    cpumem 3.74   gpumem 8.39   reserved 15.16  augment 0.167\n",
            "tick 78    kimg 312.0    time 3h 03m 41s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.74   gpumem 8.39   reserved 15.16  augment 0.174\n",
            "tick 79    kimg 316.0    time 3h 06m 02s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.74   gpumem 8.37   reserved 15.16  augment 0.175\n",
            "tick 80    kimg 320.0    time 3h 08m 22s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.74   gpumem 8.38   reserved 15.16  augment 0.173\n",
            "tick 81    kimg 324.0    time 3h 10m 42s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.1    cpumem 3.74   gpumem 8.41   reserved 15.16  augment 0.166\n",
            "tick 82    kimg 328.0    time 3h 13m 02s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.74   gpumem 8.40   reserved 15.16  augment 0.170\n",
            "tick 83    kimg 332.0    time 3h 15m 22s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.74   gpumem 8.36   reserved 15.16  augment 0.168\n",
            "tick 84    kimg 336.0    time 3h 17m 42s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.74   gpumem 8.38   reserved 15.16  augment 0.172\n",
            "tick 85    kimg 340.0    time 3h 20m 02s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.74   gpumem 8.37   reserved 15.16  augment 0.172\n",
            "tick 86    kimg 344.0    time 3h 22m 22s   sec/tick 140.0   sec/kimg 34.99   maintenance 0.0    cpumem 3.74   gpumem 8.39   reserved 15.16  augment 0.171\n",
            "tick 87    kimg 348.0    time 3h 24m 42s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.33   gpumem 8.39   reserved 15.16  augment 0.177\n",
            "tick 88    kimg 352.0    time 3h 27m 03s   sec/tick 140.1   sec/kimg 35.04   maintenance 0.0    cpumem 3.33   gpumem 8.38   reserved 15.16  augment 0.186\n",
            "tick 89    kimg 356.0    time 3h 29m 23s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.1    cpumem 3.33   gpumem 8.37   reserved 15.16  augment 0.189\n",
            "tick 90    kimg 360.0    time 3h 31m 43s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.33   gpumem 8.43   reserved 15.16  augment 0.189\n",
            "tick 91    kimg 364.0    time 3h 34m 03s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.33   gpumem 8.40   reserved 15.16  augment 0.187\n",
            "tick 92    kimg 368.0    time 3h 36m 23s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.33   gpumem 8.37   reserved 15.16  augment 0.186\n",
            "tick 93    kimg 372.0    time 3h 38m 43s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.33   gpumem 8.40   reserved 15.16  augment 0.180\n",
            "tick 94    kimg 376.0    time 3h 41m 03s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.33   gpumem 8.37   reserved 15.16  augment 0.181\n",
            "tick 95    kimg 380.0    time 3h 43m 24s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.33   gpumem 8.41   reserved 15.16  augment 0.184\n",
            "tick 96    kimg 384.0    time 3h 45m 44s   sec/tick 140.1   sec/kimg 35.01   maintenance 0.0    cpumem 3.33   gpumem 8.40   reserved 15.16  augment 0.189\n",
            "tick 97    kimg 388.0    time 3h 48m 04s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.1    cpumem 3.33   gpumem 8.42   reserved 15.16  augment 0.186\n",
            "tick 98    kimg 392.0    time 3h 50m 24s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.33   gpumem 8.40   reserved 15.16  augment 0.186\n",
            "tick 99    kimg 396.0    time 3h 52m 44s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.33   gpumem 8.37   reserved 15.16  augment 0.191\n",
            "tick 100   kimg 400.0    time 3h 55m 04s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.33   gpumem 8.38   reserved 15.16  augment 0.191\n",
            "tick 101   kimg 404.0    time 3h 57m 39s   sec/tick 140.2   sec/kimg 35.05   maintenance 14.4   cpumem 3.76   gpumem 8.38   reserved 15.16  augment 0.187\n",
            "tick 102   kimg 408.0    time 3h 59m 59s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.76   gpumem 8.41   reserved 15.16  augment 0.182\n",
            "tick 103   kimg 412.0    time 4h 02m 19s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.76   gpumem 8.39   reserved 15.16  augment 0.185\n",
            "tick 104   kimg 416.0    time 4h 04m 39s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.76   gpumem 8.39   reserved 15.16  augment 0.180\n",
            "tick 105   kimg 420.0    time 4h 06m 59s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.1    cpumem 3.76   gpumem 8.36   reserved 15.16  augment 0.177\n",
            "tick 106   kimg 424.0    time 4h 09m 20s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.76   gpumem 8.39   reserved 15.16  augment 0.183\n",
            "tick 107   kimg 428.0    time 4h 11m 40s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.76   gpumem 8.38   reserved 15.16  augment 0.184\n",
            "tick 108   kimg 432.0    time 4h 14m 00s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.76   gpumem 8.39   reserved 15.16  augment 0.186\n",
            "tick 109   kimg 436.0    time 4h 16m 20s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.76   gpumem 8.43   reserved 15.16  augment 0.186\n",
            "tick 110   kimg 440.0    time 4h 18m 40s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.76   gpumem 8.39   reserved 15.16  augment 0.188\n",
            "tick 111   kimg 444.0    time 4h 21m 00s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.76   gpumem 8.37   reserved 15.16  augment 0.193\n",
            "tick 112   kimg 448.0    time 4h 23m 20s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.76   gpumem 8.37   reserved 15.16  augment 0.184\n",
            "tick 113   kimg 452.0    time 4h 25m 41s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.1    cpumem 3.76   gpumem 8.39   reserved 15.16  augment 0.184\n",
            "tick 114   kimg 456.0    time 4h 28m 01s   sec/tick 140.3   sec/kimg 35.08   maintenance 0.0    cpumem 3.76   gpumem 8.38   reserved 15.16  augment 0.190\n",
            "tick 115   kimg 460.0    time 4h 30m 21s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.192\n",
            "tick 116   kimg 464.0    time 4h 32m 41s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.77   gpumem 8.36   reserved 15.16  augment 0.194\n",
            "tick 117   kimg 468.0    time 4h 35m 02s   sec/tick 140.3   sec/kimg 35.06   maintenance 0.0    cpumem 3.77   gpumem 8.40   reserved 15.16  augment 0.195\n",
            "tick 118   kimg 472.0    time 4h 37m 22s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.195\n",
            "tick 119   kimg 476.0    time 4h 39m 42s   sec/tick 140.3   sec/kimg 35.07   maintenance 0.0    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.201\n",
            "tick 120   kimg 480.0    time 4h 42m 02s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.77   gpumem 8.38   reserved 15.16  augment 0.207\n",
            "tick 121   kimg 484.0    time 4h 44m 22s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.1    cpumem 3.77   gpumem 8.42   reserved 15.16  augment 0.204\n",
            "tick 122   kimg 488.0    time 4h 46m 42s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.203\n",
            "tick 123   kimg 492.0    time 4h 49m 03s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.77   gpumem 8.42   reserved 15.16  augment 0.202\n",
            "tick 124   kimg 496.0    time 4h 51m 23s   sec/tick 140.1   sec/kimg 35.04   maintenance 0.0    cpumem 3.77   gpumem 8.41   reserved 15.16  augment 0.202\n",
            "tick 125   kimg 500.0    time 4h 53m 43s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.77   gpumem 8.40   reserved 15.16  augment 0.203\n",
            "tick 126   kimg 504.0    time 4h 56m 03s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.77   gpumem 8.40   reserved 15.16  augment 0.209\n",
            "tick 127   kimg 508.0    time 4h 58m 23s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.206\n",
            "tick 128   kimg 512.0    time 5h 00m 43s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.77   gpumem 8.40   reserved 15.16  augment 0.205\n",
            "tick 129   kimg 516.0    time 5h 03m 04s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.1    cpumem 3.77   gpumem 8.40   reserved 15.16  augment 0.209\n",
            "tick 130   kimg 520.0    time 5h 05m 24s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.77   gpumem 8.37   reserved 15.16  augment 0.210\n",
            "tick 131   kimg 524.0    time 5h 07m 44s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.77   gpumem 8.47   reserved 15.16  augment 0.205\n",
            "tick 132   kimg 528.0    time 5h 10m 04s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.205\n",
            "tick 133   kimg 532.0    time 5h 12m 24s   sec/tick 140.3   sec/kimg 35.07   maintenance 0.0    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.210\n",
            "tick 134   kimg 536.0    time 5h 14m 44s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.211\n",
            "tick 135   kimg 540.0    time 5h 17m 05s   sec/tick 140.3   sec/kimg 35.07   maintenance 0.0    cpumem 3.77   gpumem 8.42   reserved 15.16  augment 0.209\n",
            "tick 136   kimg 544.0    time 5h 19m 25s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.77   gpumem 8.42   reserved 15.16  augment 0.209\n",
            "tick 137   kimg 548.0    time 5h 21m 45s   sec/tick 140.1   sec/kimg 35.01   maintenance 0.1    cpumem 3.77   gpumem 8.40   reserved 15.16  augment 0.209\n",
            "tick 138   kimg 552.0    time 5h 24m 05s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.77   gpumem 8.43   reserved 15.16  augment 0.208\n",
            "tick 139   kimg 556.0    time 5h 26m 25s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.77   gpumem 8.40   reserved 15.16  augment 0.212\n",
            "tick 140   kimg 560.0    time 5h 28m 46s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.77   gpumem 8.43   reserved 15.16  augment 0.216\n",
            "tick 141   kimg 564.0    time 5h 31m 06s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.77   gpumem 8.37   reserved 15.16  augment 0.209\n",
            "tick 142   kimg 568.0    time 5h 33m 26s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.77   gpumem 8.38   reserved 15.16  augment 0.214\n",
            "tick 143   kimg 572.0    time 5h 35m 46s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.77   gpumem 8.41   reserved 15.16  augment 0.214\n",
            "tick 144   kimg 576.0    time 5h 38m 06s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.77   gpumem 8.41   reserved 15.16  augment 0.208\n",
            "tick 145   kimg 580.0    time 5h 40m 26s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.1    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.206\n",
            "tick 146   kimg 584.0    time 5h 42m 47s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.77   gpumem 8.40   reserved 15.16  augment 0.205\n",
            "tick 147   kimg 588.0    time 5h 45m 07s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.77   gpumem 8.39   reserved 15.16  augment 0.210\n",
            "tick 148   kimg 592.0    time 5h 47m 27s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.77   gpumem 8.43   reserved 15.16  augment 0.212\n",
            "tick 149   kimg 596.0    time 5h 49m 47s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.77   gpumem 8.44   reserved 15.16  augment 0.220\n",
            "tick 150   kimg 600.0    time 5h 52m 07s   sec/tick 140.0   sec/kimg 34.99   maintenance 0.0    cpumem 3.77   gpumem 8.44   reserved 15.16  augment 0.218\n",
            "tick 151   kimg 604.0    time 5h 54m 41s   sec/tick 140.2   sec/kimg 35.04   maintenance 14.3   cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.212\n",
            "tick 152   kimg 608.0    time 5h 57m 02s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.37   reserved 15.16  augment 0.213\n",
            "tick 153   kimg 612.0    time 5h 59m 22s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.1    cpumem 3.73   gpumem 8.44   reserved 15.16  augment 0.209\n",
            "tick 154   kimg 616.0    time 6h 01m 42s   sec/tick 140.1   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.212\n",
            "tick 155   kimg 620.0    time 6h 04m 02s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.16  augment 0.218\n",
            "tick 156   kimg 624.0    time 6h 06m 22s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.73   gpumem 8.43   reserved 15.16  augment 0.213\n",
            "tick 157   kimg 628.0    time 6h 08m 42s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.16  augment 0.210\n",
            "tick 158   kimg 632.0    time 6h 11m 02s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.16  augment 0.211\n",
            "tick 159   kimg 636.0    time 6h 13m 23s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.210\n",
            "tick 160   kimg 640.0    time 6h 15m 43s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.213\n",
            "tick 161   kimg 644.0    time 6h 18m 03s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.1    cpumem 3.73   gpumem 8.42   reserved 15.16  augment 0.218\n",
            "tick 162   kimg 648.0    time 6h 20m 23s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.43   reserved 15.16  augment 0.214\n",
            "tick 163   kimg 652.0    time 6h 22m 43s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.16  augment 0.212\n",
            "tick 164   kimg 656.0    time 6h 25m 03s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.43   reserved 15.16  augment 0.212\n",
            "tick 165   kimg 660.0    time 6h 27m 23s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.16  augment 0.214\n",
            "tick 166   kimg 664.0    time 6h 29m 43s   sec/tick 139.9   sec/kimg 34.99   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.16  augment 0.215\n",
            "tick 167   kimg 668.0    time 6h 32m 03s   sec/tick 140.1   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.42   reserved 15.16  augment 0.214\n",
            "tick 168   kimg 672.0    time 6h 34m 23s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.42   reserved 15.16  augment 0.215\n",
            "tick 169   kimg 676.0    time 6h 36m 44s   sec/tick 140.0   sec/kimg 34.99   maintenance 0.1    cpumem 3.73   gpumem 8.40   reserved 15.16  augment 0.218\n",
            "tick 170   kimg 680.0    time 6h 39m 04s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.16  augment 0.220\n",
            "tick 171   kimg 684.0    time 6h 41m 24s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.16  augment 0.222\n",
            "tick 172   kimg 688.0    time 6h 43m 44s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.16  augment 0.220\n",
            "tick 173   kimg 692.0    time 6h 46m 04s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.41   reserved 15.16  augment 0.218\n",
            "tick 174   kimg 696.0    time 6h 48m 24s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.36   gpumem 8.43   reserved 15.16  augment 0.225\n",
            "tick 175   kimg 700.0    time 6h 50m 44s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.36   gpumem 8.39   reserved 15.16  augment 0.222\n",
            "tick 176   kimg 704.0    time 6h 53m 04s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.36   gpumem 8.43   reserved 15.16  augment 0.231\n",
            "tick 177   kimg 708.0    time 6h 55m 24s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.1    cpumem 3.36   gpumem 8.38   reserved 15.16  augment 0.225\n",
            "tick 178   kimg 712.0    time 6h 57m 45s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.36   gpumem 8.42   reserved 15.16  augment 0.228\n",
            "tick 179   kimg 716.0    time 7h 00m 05s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.36   gpumem 8.41   reserved 15.16  augment 0.229\n",
            "tick 180   kimg 720.0    time 7h 02m 25s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.36   gpumem 8.40   reserved 15.16  augment 0.228\n",
            "tick 181   kimg 724.0    time 7h 04m 45s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.36   gpumem 8.37   reserved 15.16  augment 0.227\n",
            "tick 182   kimg 728.0    time 7h 07m 05s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.36   gpumem 8.41   reserved 15.16  augment 0.230\n",
            "tick 183   kimg 732.0    time 7h 09m 25s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.36   gpumem 8.41   reserved 15.16  augment 0.227\n",
            "tick 184   kimg 736.0    time 7h 11m 45s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.36   gpumem 8.42   reserved 15.17  augment 0.225\n",
            "tick 185   kimg 740.0    time 7h 14m 06s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.1    cpumem 3.36   gpumem 8.40   reserved 15.17  augment 0.222\n",
            "tick 186   kimg 744.0    time 7h 16m 26s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.36   gpumem 8.41   reserved 15.17  augment 0.221\n",
            "tick 187   kimg 748.0    time 7h 18m 46s   sec/tick 140.0   sec/kimg 34.99   maintenance 0.0    cpumem 3.36   gpumem 8.39   reserved 15.17  augment 0.226\n",
            "tick 188   kimg 752.0    time 7h 21m 06s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.36   gpumem 8.39   reserved 15.17  augment 0.224\n",
            "tick 189   kimg 756.0    time 7h 23m 26s   sec/tick 140.1   sec/kimg 35.04   maintenance 0.0    cpumem 3.36   gpumem 8.42   reserved 15.17  augment 0.225\n",
            "tick 190   kimg 760.0    time 7h 25m 46s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.36   gpumem 8.39   reserved 15.17  augment 0.221\n",
            "tick 191   kimg 764.0    time 7h 28m 06s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.36   gpumem 8.37   reserved 15.17  augment 0.227\n",
            "tick 192   kimg 768.0    time 7h 30m 26s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.36   gpumem 8.40   reserved 15.17  augment 0.224\n",
            "tick 193   kimg 772.0    time 7h 32m 46s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.1    cpumem 3.36   gpumem 8.42   reserved 15.17  augment 0.230\n",
            "tick 194   kimg 776.0    time 7h 35m 07s   sec/tick 140.3   sec/kimg 35.07   maintenance 0.0    cpumem 3.36   gpumem 8.40   reserved 15.17  augment 0.235\n",
            "tick 195   kimg 780.0    time 7h 37m 27s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.36   gpumem 8.39   reserved 15.17  augment 0.235\n",
            "tick 196   kimg 784.0    time 7h 39m 47s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.36   gpumem 8.40   reserved 15.17  augment 0.230\n",
            "tick 197   kimg 788.0    time 7h 42m 07s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.36   gpumem 8.42   reserved 15.17  augment 0.232\n",
            "tick 198   kimg 792.0    time 7h 44m 27s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.36   gpumem 8.38   reserved 15.17  augment 0.233\n",
            "tick 199   kimg 796.0    time 7h 46m 47s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.36   gpumem 8.42   reserved 15.17  augment 0.234\n",
            "tick 200   kimg 800.0    time 7h 49m 07s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.36   gpumem 8.43   reserved 15.17  augment 0.240\n",
            "tick 201   kimg 804.0    time 7h 51m 42s   sec/tick 140.2   sec/kimg 35.06   maintenance 14.5   cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.237\n",
            "tick 202   kimg 808.0    time 7h 54m 02s   sec/tick 140.2   sec/kimg 35.06   maintenance 0.0    cpumem 3.73   gpumem 8.41   reserved 15.17  augment 0.238\n",
            "tick 203   kimg 812.0    time 7h 56m 22s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.233\n",
            "tick 204   kimg 816.0    time 7h 58m 42s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.41   reserved 15.17  augment 0.228\n",
            "tick 205   kimg 820.0    time 8h 01m 03s   sec/tick 140.2   sec/kimg 35.05   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.234\n",
            "tick 206   kimg 824.0    time 8h 03m 23s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.239\n",
            "tick 207   kimg 828.0    time 8h 05m 43s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.45   reserved 15.17  augment 0.239\n",
            "tick 208   kimg 832.0    time 8h 08m 03s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.42   reserved 15.17  augment 0.238\n",
            "tick 209   kimg 836.0    time 8h 10m 23s   sec/tick 139.9   sec/kimg 34.98   maintenance 0.1    cpumem 3.73   gpumem 8.42   reserved 15.17  augment 0.238\n",
            "tick 210   kimg 840.0    time 8h 12m 43s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.237\n",
            "tick 211   kimg 844.0    time 8h 15m 03s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.17  augment 0.241\n",
            "tick 212   kimg 848.0    time 8h 17m 23s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.237\n",
            "tick 213   kimg 852.0    time 8h 19m 43s   sec/tick 140.1   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.17  augment 0.234\n",
            "tick 214   kimg 856.0    time 8h 22m 03s   sec/tick 140.0   sec/kimg 34.99   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.234\n",
            "tick 215   kimg 860.0    time 8h 24m 23s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.44   reserved 15.17  augment 0.236\n",
            "tick 216   kimg 864.0    time 8h 26m 43s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.241\n",
            "tick 217   kimg 868.0    time 8h 29m 03s   sec/tick 139.9   sec/kimg 34.98   maintenance 0.1    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.236\n",
            "tick 218   kimg 872.0    time 8h 31m 23s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.42   reserved 15.17  augment 0.232\n",
            "tick 219   kimg 876.0    time 8h 33m 43s   sec/tick 139.9   sec/kimg 34.99   maintenance 0.0    cpumem 3.73   gpumem 8.41   reserved 15.17  augment 0.230\n",
            "tick 220   kimg 880.0    time 8h 36m 03s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.236\n",
            "tick 221   kimg 884.0    time 8h 38m 24s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.41   reserved 15.17  augment 0.227\n",
            "tick 222   kimg 888.0    time 8h 40m 44s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.42   reserved 15.17  augment 0.232\n",
            "tick 223   kimg 892.0    time 8h 43m 04s   sec/tick 140.1   sec/kimg 35.03   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.235\n",
            "tick 224   kimg 896.0    time 8h 45m 24s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.234\n",
            "tick 225   kimg 900.0    time 8h 47m 44s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.1    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.241\n",
            "tick 226   kimg 904.0    time 8h 50m 04s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.248\n",
            "tick 227   kimg 908.0    time 8h 52m 24s   sec/tick 140.0   sec/kimg 34.99   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.249\n",
            "tick 228   kimg 912.0    time 8h 54m 44s   sec/tick 140.1   sec/kimg 35.02   maintenance 0.0    cpumem 3.73   gpumem 8.44   reserved 15.17  augment 0.246\n",
            "tick 229   kimg 916.0    time 8h 57m 04s   sec/tick 140.2   sec/kimg 35.04   maintenance 0.0    cpumem 3.73   gpumem 8.44   reserved 15.17  augment 0.248\n",
            "tick 230   kimg 920.0    time 8h 59m 24s   sec/tick 139.9   sec/kimg 34.98   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.244\n",
            "tick 231   kimg 924.0    time 9h 01m 44s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.237\n",
            "tick 232   kimg 928.0    time 9h 04m 04s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.43   reserved 15.17  augment 0.239\n",
            "tick 233   kimg 932.0    time 9h 06m 24s   sec/tick 139.9   sec/kimg 34.98   maintenance 0.1    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.234\n",
            "tick 234   kimg 936.0    time 9h 08m 44s   sec/tick 140.1   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.226\n",
            "tick 235   kimg 940.0    time 9h 11m 04s   sec/tick 139.9   sec/kimg 34.97   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.232\n",
            "tick 236   kimg 944.0    time 9h 13m 24s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.38   reserved 15.17  augment 0.241\n",
            "tick 237   kimg 948.0    time 9h 15m 44s   sec/tick 140.0   sec/kimg 35.01   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.243\n",
            "tick 238   kimg 952.0    time 9h 18m 04s   sec/tick 139.9   sec/kimg 34.97   maintenance 0.0    cpumem 3.73   gpumem 8.42   reserved 15.17  augment 0.239\n",
            "tick 239   kimg 956.0    time 9h 20m 24s   sec/tick 140.0   sec/kimg 35.00   maintenance 0.0    cpumem 3.73   gpumem 8.39   reserved 15.17  augment 0.234\n",
            "tick 240   kimg 960.0    time 9h 22m 44s   sec/tick 139.9   sec/kimg 34.98   maintenance 0.0    cpumem 3.73   gpumem 8.45   reserved 15.17  augment 0.239\n",
            "tick 241   kimg 964.0    time 9h 25m 04s   sec/tick 139.9   sec/kimg 34.97   maintenance 0.1    cpumem 3.73   gpumem 8.44   reserved 15.17  augment 0.246\n",
            "tick 242   kimg 968.0    time 9h 27m 24s   sec/tick 139.9   sec/kimg 34.98   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.249\n",
            "tick 243   kimg 972.0    time 9h 29m 44s   sec/tick 139.8   sec/kimg 34.96   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.249\n",
            "tick 244   kimg 976.0    time 9h 32m 04s   sec/tick 139.9   sec/kimg 34.96   maintenance 0.0    cpumem 3.73   gpumem 8.43   reserved 15.17  augment 0.252\n",
            "tick 245   kimg 980.0    time 9h 34m 24s   sec/tick 139.9   sec/kimg 34.98   maintenance 0.0    cpumem 3.73   gpumem 8.43   reserved 15.17  augment 0.244\n",
            "tick 246   kimg 984.0    time 9h 36m 43s   sec/tick 139.8   sec/kimg 34.96   maintenance 0.0    cpumem 3.73   gpumem 8.40   reserved 15.17  augment 0.247\n",
            "tick 247   kimg 988.0    time 9h 39m 03s   sec/tick 140.0   sec/kimg 34.99   maintenance 0.0    cpumem 3.73   gpumem 8.41   reserved 15.17  augment 0.249\n",
            "tick 248   kimg 992.0    time 9h 41m 23s   sec/tick 139.9   sec/kimg 34.97   maintenance 0.0    cpumem 3.73   gpumem 8.41   reserved 15.17  augment 0.248\n",
            "tick 249   kimg 996.0    time 9h 43m 43s   sec/tick 139.8   sec/kimg 34.95   maintenance 0.1    cpumem 3.73   gpumem 8.43   reserved 15.17  augment 0.249\n",
            "tick 250   kimg 1000.0   time 9h 46m 03s   sec/tick 139.4   sec/kimg 34.99   maintenance 0.0    cpumem 3.73   gpumem 8.48   reserved 15.17  augment 0.244\n",
            "\n",
            "Exiting...\n",
            "Using model: /content/van_gogh_gan/models/00002-stylegan3-r-vangogh-gpus1-batch16-gamma10/network-snapshot-001000.pkl\n",
            "Generating samples...\n",
            "Loading networks from \"/content/van_gogh_gan/models/00002-stylegan3-r-vangogh-gpus1-batch16-gamma10/network-snapshot-001000.pkl\"...\n",
            "Generating image for seed 0 (0/16) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... /usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Done.\n",
            "Generating image for seed 1 (1/16) ...\n",
            "Generating image for seed 2 (2/16) ...\n",
            "Generating image for seed 3 (3/16) ...\n",
            "Generating image for seed 4 (4/16) ...\n",
            "Generating image for seed 5 (5/16) ...\n",
            "Generating image for seed 6 (6/16) ...\n",
            "Generating image for seed 7 (7/16) ...\n",
            "Generating image for seed 8 (8/16) ...\n",
            "Generating image for seed 9 (9/16) ...\n",
            "Generating image for seed 10 (10/16) ...\n",
            "Generating image for seed 11 (11/16) ...\n",
            "Generating image for seed 12 (12/16) ...\n",
            "Generating image for seed 13 (13/16) ...\n",
            "Generating image for seed 14 (14/16) ...\n",
            "Generating image for seed 15 (15/16) ...\n",
            "Backing up results to Google Drive...\n",
            "\n",
            "All results saved to Google Drive at: /content/drive/MyDrive/van_gogh_gan\n",
            "Generated images are in: /content/drive/MyDrive/van_gogh_gan/results/samples/\n",
            "The trained model is saved as: /content/drive/MyDrive/van_gogh_gan/network-snapshot-001000.pkl\n",
            "Pipeline completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Метрики"
      ],
      "metadata": {
        "id": "0j--Ply7P_pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- install & setup  -----------------------\n",
        "!pip install -q ninja scipy opencv-python matplotlib lpips kagglehub torch torchvision\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "DRIVE_DIR = \"/content/drive/MyDrive/van_gogh_gan\"\n",
        "SNAPSHOT  = f\"network-snapshot-001000.pkl\"\n",
        "\n",
        "import os, sys, glob, random, csv, torch, numpy as np, torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- StyleGAN3 ---------------------------------------------------------------\n",
        "!rm -rf stylegan3; git clone -q https://github.com/NVlabs/stylegan3.git\n",
        "sys.path.append(\"/content/stylegan3\")\n",
        "import dnnlib, legacy\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "assert os.path.isfile(SNAPSHOT), \"⛔️ snapshot not found!\"\n",
        "\n",
        "with dnnlib.util.open_url(SNAPSHOT) as f:\n",
        "    G = legacy.load_network_pkl(f)['G_ema'].to(device).eval()\n",
        "\n",
        "# --- prepare dataset ---------------------------------------------------------\n",
        "import kagglehub\n",
        "data_root = kagglehub.dataset_download(\"ipythonx/van-gogh-paintings\")\n",
        "real_pool = sum([glob.glob(f\"{data_root}/**/*{ext}\", recursive=True)\n",
        "                 for ext in ('.jpg', '.jpeg', '.png')], [])\n",
        "\n",
        "prep = T.Compose([T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])\n",
        "\n",
        "# --- metric helpers ----------------------------------------------------------\n",
        "from lpips import LPIPS\n",
        "lpips_fn = LPIPS(net='vgg').to(device).eval()\n",
        "\n",
        "from torchvision.models import vgg16, VGG16_Weights\n",
        "vgg = vgg16(weights=VGG16_Weights.IMAGENET1K_V1).features[:16].to(device).eval()\n",
        "style_layers = {1, 6, 11}\n",
        "def gram(x):\n",
        "    b,c,h,w = x.shape\n",
        "    f = x.view(b, c, h*w)\n",
        "    return f @ f.transpose(1,2) / (c*h*w)\n",
        "def style_loss(a, b):\n",
        "    loss, g, r = 0.0, a, b\n",
        "    with torch.no_grad():\n",
        "        for i, layer in enumerate(vgg):\n",
        "            g, r = layer(g), layer(r)\n",
        "            if i in style_layers:\n",
        "                loss += F.mse_loss(gram(g), gram(r))\n",
        "    return loss.item()\n",
        "\n",
        "# --- main loop ---------------------------------------------------------------\n",
        "N_SAMPLES = 50\n",
        "TRUNC     = 0.7\n",
        "\n",
        "lpips_vals, style_vals = [], []\n",
        "out_dir = \"/content/samples\"; os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "for seed in tqdm(range(N_SAMPLES), desc=\"Evaluating\"):\n",
        "    # generate\n",
        "    z = torch.from_numpy(np.random.RandomState(seed).randn(1, G.z_dim)).to(device)\n",
        "    gen = (G(z, None, truncation_psi=TRUNC, noise_mode='const').clamp(-1,1)+1)/2\n",
        "    # pick real\n",
        "    real_pil = Image.open(random.choice(real_pool)).convert('RGB')\n",
        "    w,h = real_pil.size; s=min(w,h)\n",
        "    real_pil = real_pil.crop(((w-s)//2, (h-s)//2, (w+s)//2, (h+s)//2)).resize((256,256), Image.LANCZOS)\n",
        "\n",
        "    gen_t  = prep(T.ToPILImage()(gen[0].cpu())).unsqueeze(0).to(device)\n",
        "    real_t = prep(real_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    lp = lpips_fn(gen_t, real_t).item()\n",
        "    st = style_loss(gen_t, real_t)\n",
        "\n",
        "    lpips_vals.append(lp); style_vals.append(st)\n",
        "\n",
        "    # опционально сохраняем генерацию раз в 10, чтобы глазом проверить\n",
        "    if seed % 10 == 0:\n",
        "        T.ToPILImage()(gen[0].cpu()).save(f\"{out_dir}/seed{seed:03d}.png\")\n",
        "\n",
        "# --- summary -----------------------------------------------------------------\n",
        "import math, pandas as pd, json, pprint\n",
        "mean_lp, std_lp = np.mean(lpips_vals), np.std(lpips_vals)\n",
        "mean_st, std_st = np.mean(style_vals), np.std(style_vals)\n",
        "\n",
        "print(f\"\\nLPIPS  : μ={mean_lp:.4f}  σ={std_lp:.4f}\")\n",
        "print(f\"StyleL.: μ={mean_st:.4f}  σ={std_st:.4f}\")\n",
        "\n",
        "# сохраняем подробный лог\n",
        "csv_path = f\"{out_dir}/metrics_{N_SAMPLES}s.csv\"\n",
        "with open(csv_path, 'w', newline='') as f:\n",
        "    w = csv.writer(f); w.writerow(['seed','lpips','style_loss'])\n",
        "    w.writerows(zip(range(N_SAMPLES), lpips_vals, style_vals))\n",
        "print(f\"→ CSV с результатами: {csv_path}\")\n",
        "\n",
        "# бэкап в Drive\n",
        "!cp -r /content/samples {DRIVE_DIR}/results/ 2>/dev/null || true\n",
        "print(f\"Everything backed up to {DRIVE_DIR}/results/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515,
          "referenced_widgets": [
            "77436cc4006b44dbb106a3fdd640312a",
            "fe9af3614f4a46cebe288b5cbf2f2e31",
            "165d852df0a346a391a072747b8472a9",
            "11b2ff3a707f4a9ca5c17d9de8505462",
            "bbe2219085dc402a82ce2cf78ee50c49",
            "dff2d3742e5b49c4a3bf25d7913cd493",
            "0cce1613c8964f93aec8760ef0dcdee2",
            "1f45d4c28cef4dc7a78cf08e4d0d0019",
            "fa1738da20bf429db6bf280a4148d101",
            "7ca7180195bb4a019a6c5cfd299c3337",
            "250a93a6a5db4922a550e3aad03e4f26"
          ]
        },
        "id": "q3uy3rsBP-7h",
        "outputId": "9f1cb424-dc53-457e-db9d-5e7d4e83037e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ipythonx/van-gogh-paintings?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 485M/485M [00:24<00:00, 21.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:02<00:00, 231MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77436cc4006b44dbb106a3fdd640312a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up PyTorch plugin \"bias_act_plugin\"... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "\n",
            "LPIPS  : μ=0.7108  σ=0.0551\n",
            "StyleL.: μ=0.0000  σ=0.0000\n",
            "→ CSV с результатами: /content/samples/metrics_50s.csv\n",
            "Everything backed up to /content/drive/MyDrive/van_gogh_gan/results/\n"
          ]
        }
      ]
    }
  ]
}